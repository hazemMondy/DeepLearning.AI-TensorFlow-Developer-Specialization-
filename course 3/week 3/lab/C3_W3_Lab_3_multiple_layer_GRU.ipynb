{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/adding_C3/C3/W3/ungraded_labs/C3_W3_Lab_3_multiple_layer_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFiCyWQ-NC5D"
      },
      "source": [
        "# Multiple Layer GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y20Lud2ZMBhW"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AW-4Vo4TMUHb"
      },
      "outputs": [],
      "source": [
        "# Get the data\n",
        "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True, as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "tokenizer = info.features['text'].encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffvRUI0_McDS"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(train_dataset))\n",
        "test_dataset = test_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "you will use Conv1D instead so the convolution will happen over a single dimension. You will also append a pooling layer to reduce the output of the convolution layer.\n",
        "\n",
        "you will use GlobalMaxPooling1D to get the max value across the time dimension. \n",
        "\n",
        "You can also use average pooling and you will do that in the next labs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch_size: 1\n",
            "timesteps (sequence length): 20\n",
            "features (embedding size): 20\n",
            "filters: 128\n",
            "kernel_size: 5\n",
            "shape of input array: (1, 20, 20)\n",
            "shape of conv1d output: (1, 16, 128)\n",
            "shape of global max pooling output: (1, 128)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 1\n",
        "timesteps = 20\n",
        "features = 20\n",
        "filters = 128\n",
        "kernel_size = 5\n",
        "\n",
        "print(f'batch_size: {batch_size}')\n",
        "print(f'timesteps (sequence length): {timesteps}')\n",
        "print(f'features (embedding size): {features}')\n",
        "print(f'filters: {filters}')\n",
        "print(f'kernel_size: {kernel_size}')\n",
        "\n",
        "# Define array input with random values\n",
        "random_input = np.random.rand(batch_size,timesteps,features)\n",
        "print(f'shape of input array: {random_input.shape}')\n",
        "\n",
        "# Pass array to convolution layer and inspect output shape\n",
        "conv1d = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')\n",
        "result = conv1d(random_input)\n",
        "print(f'shape of conv1d output: {result.shape}')\n",
        "\n",
        "# Pass array to max pooling layer and inspect output shape\n",
        "gmp = tf.keras.layers.GlobalMaxPooling1D()\n",
        "result = gmp(result)\n",
        "print(f'shape of global max pooling output: {result.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo1jjO3vn0jo"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),\n",
        "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mlgzaRDMtF6"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 10\n",
        "history = model.fit(train_dataset, epochs=NUM_EPOCHS, validation_data=test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mp1Z7P9pYRSK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_sX6ilIM515"
      },
      "outputs": [],
      "source": [
        "plot_graphs(history, 'accuracy')\n",
        "plot_graphs(history, 'loss')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "C3_W3_Lab_3_multiple_layer_GRU.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
